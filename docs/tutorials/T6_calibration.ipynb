{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19fb22f4",
   "metadata": {},
   "source": [
    "# Model Calibration\n",
    "## Why calibrate?\n",
    "Calibration is the process of fine-tuning an agent-based model's input parameters so that its simulated outputs align with real-world data. Without calibration, the model might generate plausible-looking behavior that doesn’t actually reflect reality. Calibration improves the model’s credibility, predictive power, and policy relevance by ensuring it reproduces key observed patterns or outcomes from historical data.\n",
    "\n",
    "## Calibration Process Overview\n",
    "1. Define Calibration Targets:\n",
    "Select measurable real-world data points (e.g., population size, disease prevalence, contraceptive use) that the model should replicate.\n",
    "\n",
    "2. Identify Parameters to Tune:\n",
    "Choose uncertain model parameters that strongly influence the outcomes but lack precise empirical estimates (e.g., agent behavior probabilities, environmental factors, etc.).\n",
    "\n",
    "3. Choose a Calibration Method:\n",
    "Use either:\n",
    "- Manual/heuristic tuning (trial-and-error or expert knowledge), or\n",
    "- Automated optimization (e.g., grid search, random search, genetic algorithms, or Bayesian methods) to systematically explore parameter space.\n",
    "\n",
    "4. Define a Goodness-of-Fit Metric:\n",
    "Quantify how well the model output matches the targets using metrics like root mean squared error (RMSE), likelihood scores, or custom error functions.\n",
    "\n",
    "5. Run the Calibration:\n",
    "Simulate the model repeatedly with different parameter values and evaluate performance using the fit metric.\n",
    "\n",
    "6. Select Best-Fit Parameters:\n",
    "Identify parameter sets that produce model outputs closest to observed data.\n",
    "\n",
    "7. Validate (if possible):\n",
    "Use separate data not involved in calibration to assess the model’s generalizability.\n",
    "\n",
    "In this tutorial, we will walk through the basics of running both a manual and automated calibration. Choosing between manual and automated calibration depends on the model complexity, parameter uncertainty, available data, and computational resources. \n",
    "\n",
    "## Manual Calibration\n",
    "Manual calibration involves adjusting parameters by hand based on expert knowledge or visual inspection of outputs. This can make sense when:\n",
    "- The model has few parameters to tune\n",
    "- You have strong domain knowledge about parameter ranges\n",
    "- You are in the early stages of model development or prototyping\n",
    "- The simulation is computationally expensive or you have limited computational resources\n",
    "- You want to explore model behavior qualitatively\n",
    "\n",
    "The plotting class (in plotting.py) can be used to visually inspect the outputs of common target parameters (e.g. CPR, method mix, TFR, etc.) and compare the model output vs real-world data.\n",
    "\n",
    "## Automated Calibration\n",
    "Automated calibration uses optimization algorithms (like Optuna’s Bayesian optimization) to efficiently search parameter space for the best fit. An automated calibration in FPsim uses the calibration and experiment classes to use Optuna's optimization methods to determine the best free parameters. This makes sense to use when:\n",
    "- Your model has many uncertain parameters (e.g. 5+)\n",
    "- You have access to compute resources to run many simulations (e.g. in parallel on a machine or VM with ample processing power, memory, and storage OR on a cloud computing platform)\n",
    "- You have a large number of target parameters to which you want to calibrate with an unbiased approach\n",
    " \n",
    "A hybrid approach can also be to start with a manual calibration to narrow down plausible ranges and understand model dynamics. Then switch to automated methods to fine-tune parameters and formalize the process. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e99e47",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "\n",
    "In order to run a calibration successfully, we need to ensure that the fpsim/locations directory contains a directory for the country being calibrated (i.e. 'fpsim/locations/kenya'). This directory should also contain:\n",
    "- A model file (i.e. fpsim/locations/kenya/kenya.py)\n",
    "- A data subdirectory with data for the desired calibration targets (see fpsim/locations/README.md for specific files and means of generating each), ideally with the most recently available comprehensive data to compare with the model output \n",
    "\n",
    "Ensure that the data in the aforementioned files are formatted in the same manner as those in `locations/kenya/data`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31bbec8",
   "metadata": {},
   "source": [
    "## Running a Manual Calibration\n",
    "### Imports\n",
    "First, we import any needed packages. We also import the plotting class, which is useful in visually inspecting the model vs observed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd4ee2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fpsim as fp\n",
    "from fpsim import plotting as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f10d67",
   "metadata": {},
   "source": [
    "### Setting Parameters\n",
    "\n",
    "First, we set up our parameters for the simulation(s) used for calibration, including the country name and any specific sim params, such as the population size and start/end year of the sim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3264f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "country = 'kenya'\n",
    "pars = fp.all_pars(location=country)  # For default pars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a3421f0adfd55d",
   "metadata": {},
   "source": [
    "Next we set our free parameters to initial values that we will iteratively tune to optimize the model outputs (to be as close as possible to real-world data). The free parameters below are used for tuning:\n",
    "- fecundity_var_low, fecundity_var_high\n",
    "- exposure_factor\n",
    "- spacing_pref\n",
    "- primary_infertility\n",
    "- age-based exposure (modified in {country}.py)\n",
    "- parity-based exposure (modified in {country}.py)\n",
    "\n",
    "We can also modify the contraceptive choice parameters, which can be useful especially in adjusting the model contraceptive prevalence rate. The `prob_use_year` parameter is helpful to adjust the CPR starting point (seen in the CPR trend plot), and the `prob_use_trend_par` parameter is helpful to adjust the slope in the CPR trend plot. Lastly, the `method_weights` array parameter is useful in tuning the method mix, for example - increasing the % of pill use and decreasing the % of IUD use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f46c591a62a32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial free parameters for calibration\n",
    "pars['exposure_factor'] = 1\n",
    "\n",
    "# Postpartum sexual activity correction or 'birth spacing preference'. Pulls values from {location}/data/birth_spacing_pref.csv by default\n",
    "# Set all to 1 to reset. Option to use 'optimize-space-prefs.py' script in this directory to determine values\n",
    "pars['spacing_pref']['preference'][:3] =  1  # Spacing of 0-6 months\n",
    "pars['spacing_pref']['preference'][3:6] = 1  # Spacing of 9-15 months\n",
    "pars['spacing_pref']['preference'][6:9] = 1  # Spacing of 18-24 months\n",
    "pars['spacing_pref']['preference'][9:] =  1  # Spacing of 27-36 months\n",
    "\n",
    "# Only other simulation free parameters are age-based exposure and parity-based exposure (which you can adjust manually in {country}.py) as well as primary_infertility (set to 0.05 by default)\n",
    "\n",
    "# Adjust contraceptive choice parameters\n",
    "cm_pars = dict(\n",
    "    prob_use_year=2020,  # Time trend intercept\n",
    "    prob_use_trend_par=0.06,   # Time trend parameter\n",
    "    method_weights=np.array([1, 1, 1, 1, 1, 1, 1, 1, 1])  # Weights for the methods in method_list in methods.py (excluding 'none', so starting with 'pill' and ending in 'othmod').\n",
    ")\n",
    "method_choice = fp.SimpleChoice(pars=cm_pars, location=country)     # The contraceptive choice module used (see methods.py for more documentation). We can select RandomChoice, SimpleChoice, or StandardChoice (StandardChoice is selected by default)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f704d358d1a64428",
   "metadata": {},
   "source": [
    "### Running the Simulation\n",
    "\n",
    "We run the simulation with the free parameters specified above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa73144703c03cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the sim\n",
    "sim = fp.Sim(pars=pars, contraception_module=method_choice)\n",
    "sim.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413fee59",
   "metadata": {},
   "source": [
    "### Plotting the Target Parameters\n",
    "\n",
    "Once the sim run completes, we plot the sim results and the target parameters (comparing the model results vs real-world data). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19344b9cd60b0098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sim\n",
    "sim.plot()\n",
    "\n",
    "# Plotting class function which plots the primary calibration targets (method mix, method use, cpr, total fertility rate, birth spacing, age at first birth, and age-specific fertility rate)\n",
    "plt.plot_calib(sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0629cbeca920e5",
   "metadata": {},
   "source": [
    "We can see from the plots above that compared to the real-world data in 2020, our model has some adjustments that need to be made. We do this iteratively to see how we can get specific target parameters closer to reality. For example, the model currently results in a TFR that is too low, and the birth space bins have discrepancies (0-12mo is too high, 12-24mo is too high, and 24-48mo is too low). We can modify the free parameters to tune the model to adjust accordingly. Let's try increasing the exposure factor to increase the TFR and modifying the spacing preference factors to account for the current model/data differences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92bad23b6318a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial free parameters for calibration\n",
    "pars['exposure_factor'] = 1\n",
    "\n",
    "# Last free parameter, postpartum sexual activity correction or 'birth spacing preference'. Pulls values from {location}/data/birth_spacing_pref.csv by default\n",
    "# Set all to 1 to reset. Option to use 'optimize-space-prefs.py' script in this directory to determine values\n",
    "pars['spacing_pref']['preference'][:4] = .4  # Spacing of 0-12 months\n",
    "pars['spacing_pref']['preference'][4:8] = .2  # Spacing of 12-24 months\n",
    "pars['spacing_pref']['preference'][8:16] = 2  # Spacing of 24-48 months\n",
    "pars['spacing_pref']['preference'][16:] = 1  # Spacing of >48 months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eff3f2025f5dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-run the sim\n",
    "method_choice = fp.SimpleChoice(pars=cm_pars, location=country) \n",
    "sim = fp.Sim(pars=pars, contraception_module=method_choice)\n",
    "sim.run()\n",
    "plt.plot_calib(sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a00177b6494dd9f",
   "metadata": {},
   "source": [
    "Our adjustments helped move the model results towards the real-world trends thankfully! As we iteratively modify the free parameters, we can both improve the calibration of the model and simultaneously learn how the parameters affect the model behavior. For example, as increasing the exposure_factor increased the TFR (which is still too low), we can increase it again in hopes of making it closer to the data. \n",
    "\n",
    "There are different strategies of fine-tuning these parameters manually, but one method is to modify the free parameters to get 1-2 target parameters as close as we can before then focusing on a different target parameter to improve via additional free parameter modifications. As these models are quite dynamic, changing one free parameter will often change several target parameters (some more significantly than others); thus, it's worth taking note of which target parameters change and in what direction(s). \n",
    "\n",
    "There is an initial learning curve to understanding which free parameters affect which target parameters, but tuning the model by visual inspection of model vs data in the plots becomes easier and quicker over time.\n",
    "\n",
    "Let's try increasing the exposure_factor once more and also modifying one of the contraceptive choice parameters (`method_weights`) to calibrate the method mix (increasing weights for those with percentages too low and decreasing weights for those with percentages too high):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e030decca2602d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial free parameters for calibration\n",
    "pars['exposure_factor'] = 1\n",
    "\n",
    "# Last free parameter, postpartum sexual activity correction or 'birth spacing preference'. Pulls values from {location}/data/birth_spacing_pref.csv by default\n",
    "# Set all to 1 to reset. Option to use 'optimize-space-prefs.py' script in this directory to determine values\n",
    "pars['spacing_pref']['preference'][:4] = .4  # Spacing of 0-12 months\n",
    "pars['spacing_pref']['preference'][4:8] = .2  # Spacing of 12-24 months\n",
    "pars['spacing_pref']['preference'][8:16] = 2  # Spacing of 24-48 months\n",
    "pars['spacing_pref']['preference'][16:] = 1  # Spacing of >48 months\n",
    "\n",
    "# Adjust contraceptive choice parameters\n",
    "cm_pars = dict(\n",
    "    prob_use_year=2020,  # Time trend intercept\n",
    "    prob_use_trend_par=0.06,   # Time trend parameter\n",
    "    force_choose=False,        # Whether to force non-users to choose a method ('False' by default)\n",
    "    method_weights=np.array([.5, .5, 1, .7, 1, 1, 1.3, .8, 3])  # Weights for the methods in method_list in methods.py (excluding 'none', so starting with 'pill' and ending in 'othmod').\n",
    ")\n",
    "method_choice = fp.SimpleChoice(pars=cm_pars, location=country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2accd79baef72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-run the sim\n",
    "sim = fp.Sim(pars=pars, contraception_module=method_choice)\n",
    "sim.run()\n",
    "plt.plot_calib(sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e0dfbcbbd3cc52",
   "metadata": {},
   "source": [
    "Both of these changes helped us improve these target parameters! The TFR (and ASFR) both shifted closer to the data, and the method mix looks much closer as well. As was mentioned however, changing free parameters doesn't necessarily adjust target parameters 1-1 (they rarely do!); notice how these changes resulted in the birth space bin of 12-24mo jumping back up when we had tuned it to be lower (and closer to the data) previously. The good news is that we already learned how to adjust the birth space bins by modifying the spacing_pref param; thus, we can keep the free parameters we've adjusted so far and decrease the spacing_pref 12-24mo weight again to continue the calibration. \n",
    "\n",
    "We continue in this manner, iteratively improving the target parameters to which we are calibrating. We can either calibrate solely in this manner (if limited in computational resources and/or in the early stages of model development), or we can perform an approximate calibration and then use the chosen free parameters to help narrow the parameter ranges we want to sweep in an automatic calibration. Automatic calibration will be covered in a forthcoming tutorial."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
